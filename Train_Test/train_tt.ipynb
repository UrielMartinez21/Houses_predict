{"cells":[{"cell_type":"markdown","metadata":{"id":"-SG_a0_Iu7xb"},"source":["## Instalar bibliotecas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27266,"status":"ok","timestamp":1708889256207,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"_gp_Zeomu_Z4","outputId":"40e8c45b-5587-4e40-f090-d94a42b5060a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"]}],"source":["!pip install torch                    # Install the PyTorch library for deep learning.\n","!pip install pandas                   # Install the Pandas library for data manipulation.\n","!pip install scikit-learn             # Install scikit-learn for machine learning tasks.\n","!pip install sentencepiece            # Install SentencePiece for text tokenization."]},{"cell_type":"markdown","metadata":{"id":"ivYF87NnpNJJ"},"source":["## Leer archivos de drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28682,"status":"ok","timestamp":1710096093396,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"-LRYFJTSpRVJ","outputId":"4230e83a-0ded-46e9-fb0f-ff51a53c3dc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","imagenes_mosaico  test_mosaico.csv  train_mosaico.csv\n"]}],"source":["from google.colab import drive\n","\n","# Montar Google Drive en /content/drive\n","drive.mount('/content/drive')\n","\n","# Listar archivos en el directorio raíz de Google Drive\n","!ls '/content/drive/MyDrive/Dataset/'"]},{"cell_type":"markdown","metadata":{"id":"VolxACn_wRiE"},"source":["## Bibliotecas"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":133,"status":"ok","timestamp":1710096370569,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"GFRklsdxwTfM"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from torchvision.io import read_image\n","from torchvision import transforms, utils\n","from torch.utils.data import Dataset, DataLoader,ConcatDataset\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from torch import nn\n","from torch import optim\n","import datetime\n","from PIL import Image"]},{"cell_type":"markdown","metadata":{"id":"8dWxXP-am2Et"},"source":["## Cargar datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":240,"status":"ok","timestamp":1710096475866,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"78-BEfeXm2Ex","outputId":"b0ae0c0a-9be8-4767-ccd4-0ca4d0976f02"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>imagen_mosaico</th>\n","      <th>bathrooms</th>\n","      <th>bedrooms</th>\n","      <th>area</th>\n","      <th>zipcode</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>285.png</td>\n","      <td>5.0</td>\n","      <td>5</td>\n","      <td>3816</td>\n","      <td>92880</td>\n","      <td>589900</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>348.png</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","      <td>1440</td>\n","      <td>92276</td>\n","      <td>106000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>441.png</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>1625</td>\n","      <td>93510</td>\n","      <td>639000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>422.png</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>2454</td>\n","      <td>93510</td>\n","      <td>5858000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>150.png</td>\n","      <td>4.5</td>\n","      <td>4</td>\n","      <td>4038</td>\n","      <td>92677</td>\n","      <td>1795000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  imagen_mosaico  bathrooms  bedrooms  area  zipcode    price\n","0        285.png        5.0         5  3816    92880   589900\n","1        348.png        2.0         2  1440    92276   106000\n","2        441.png        3.0         4  1625    93510   639000\n","3        422.png        3.0         4  2454    93510  5858000\n","4        150.png        4.5         4  4038    92677  1795000"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# df_train = pd.read_csv('/content/drive/MyDrive/Dataset/train_mosaico.csv')\n","df_train = pd.read_csv('../Dataset/train.csv')\n","\n","df_train.head()"]},{"cell_type":"markdown","metadata":{"id":"qU8R_9j4vvWk"},"source":["## Procesar dataset(imagenes y datos categoricos)\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":208,"status":"ok","timestamp":1710096514580,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"tX3K47RevxpH"},"outputs":[],"source":["class ProcesarDataset(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform  # Transformación de la imagen\n","        # self.onehot = onehot        # Codificación one-hot para categorías\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        # Obtener fila del registro\n","        tabular = self.df.iloc[idx, :]\n","\n","        # Precio de la casa\n","        price = tabular['price']\n","\n","        # Obtener imagen\n","        # imgs = read_image(f\"/content/drive/MyDrive/Dataset/imagenes_mosaico/{tabular['imagen_mosaico']}\").float()\n","        imgs = read_image(f\"../Dataset/imagenes_mosaico/{tabular['imagen_mosaico']}\").float()\n","\n","        # Transformar imagen\n","        try:\n","          if self.transform:\n","            imgs = self.transform(imgs)\n","        except:\n","          print(\"[-]Algo ocurrio con la transformarción de la imagen\")\n","\n","        # Convertir datos tabulares a tensores\n","        tabular = tabular[[\"bathrooms\", \"bedrooms\", \"area\", \"zipcode\"]]\n","        tabular = tabular.tolist()\n","        numeric_features = torch.FloatTensor(tabular)\n","\n","        # Regresar tupla de valores\n","        # return image, tabular, y\n","        return imgs, numeric_features, price\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1710096417393,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"oAOuuD2w47By","outputId":"7daae71a-832e-4d2b-f2f5-ef0c35c5dd9e"},"outputs":[{"data":{"text/plain":["589900"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataset = ProcesarDataset(df_train)\n","\n","dataset[0][-1]"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":138,"status":"ok","timestamp":1710096229008,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"CtMFRJiNNPLU"},"outputs":[],"source":["dataset = ProcesarDataset(\n","    df = df_train,\n","    transform = transforms.Compose(\n","        [\n","            transforms.Resize(256),\n","            transforms.RandomCrop((224,224)),\n","            transforms.Normalize(\n","                (58.0583, 55.1679, 52.9831),\n","                (85.9875, 82.3628, 80.8718))\n","        ]\n","    )\n",")\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":211,"status":"ok","timestamp":1710096236348,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"5584ugDShyDi"},"outputs":[],"source":["# Especifica la longitud para el conjunto de entrenamiento y validación\n","train_size = int(0.8 * len(df_train))\n","val_size = len(df_train) - train_size\n","\n","# Divide el conjunto de datos\n","train_data, val_data = torch.utils.data.random_split(dataset, [train_size, val_size])"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":131,"status":"ok","timestamp":1710096251103,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"4kslUGzCh3kC"},"outputs":[],"source":["# Establece el tamaño del lote (batch_size) que se utilizará durante el entrenamiento.\n","batch_size = 64\n","\n","# Crea un DataLoader para el conjunto de entrenamiento (train_data).\n","# - batch_size: Número de muestras en cada lote.\n","# - shuffle: Mezcla los datos en cada época para introducir variabilidad en el entrenamiento.\n","train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","\n","# Crea un DataLoader para el conjunto de validación (val_data).\n","# - batch_size: Número de muestras en cada lote.\n","# - shuffle: Mezcla los datos en cada época para introducir variabilidad en la validación.\n","val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n"]},{"cell_type":"markdown","metadata":{"id":"RZY1E-eNnd7E"},"source":["## Arquitectura"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":165,"status":"ok","timestamp":1710096282584,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"xgHKnloonhgP"},"outputs":[],"source":["# Definición de una red neuronal utilizando la clase nn.Module de PyTorch.\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","\n","        # Capas para procesar características de imágenes\n","        self.image_features_ = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Dropout(),\n","            nn.Conv2d(16, 128, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Dropout(),\n","            nn.Conv2d(128, 256, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Dropout(),\n","            nn.Conv2d(256, 128, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(128, 64, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","\n","        # Capas para procesar características numéricas\n","        self.numeric_features_ = nn.Sequential(\n","            nn.Linear(9, 64),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(64, 64*3),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(64*3, 64*3*3),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        # Capas para combinar características de imágenes y numéricas\n","        self.combined_features_ = nn.Sequential(\n","            nn.Linear(64*3*3*2, 64*3*3*2*2),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(64*3*3*2*2, 64*3*3*2),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(64*3*3*2, 64),\n","            nn.Linear(64, 5),\n","        )\n","\n","    def forward(self, x, y):\n","        # Propagación hacia adelante\n","        x = self.image_features_(x)\n","        x = x.view(-1, 64*3*3)\n","        # x = x.view(-1, 20*20*128)\n","        y = self.numeric_features_(y)\n","        z = torch.cat((x, y), 1)\n","        z = self.combined_features_(z)\n","        return z\n"]},{"cell_type":"markdown","metadata":{"id":"tT-dC4h9iV0E"},"source":["## Funciones de optimización y de perdida"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183,"status":"ok","timestamp":1710096310381,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"sqwJAJ8liaia","outputId":"966d9e24-94f4-4e22-e6f5-d4cf825a56fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["[+]Se esta usando: cpu\n"]}],"source":["# Tipo de dispositivo a usar\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('[+]Se esta usando: {}'.format(device))\n","\n","# Mandar modelo a dispositivo\n","model = NeuralNetwork().to(device)\n","\n","# Crear funciones de optimización y perdida\n","optimizer=optim.Adam(model.parameters(),1e-3)\n","loss_fn=nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"id":"tZuGjalVq-VL"},"source":["## Funciones de train y test"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":137,"status":"ok","timestamp":1710096318236,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"uhJO_Okqq8L_"},"outputs":[],"source":["def test_loop(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for imgs,numeric_features, price in dataloader:\n","            imgs=imgs.to(device)\n","            numeric_features=numeric_features.to(device)\n","            price = price.to(device)\n","            pred = model(imgs,numeric_features)\n","            test_loss += loss_fn(pred, price).item()\n","            correct += (pred.argmax(1) == price).type(torch.float).sum().item()\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":123,"status":"ok","timestamp":1710096321230,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"MF-YzUo5rPDV"},"outputs":[],"source":["import datetime\n","\n","def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader):\n","\n","    print(\"Número de lotes en train_loader:\", len(train_loader))\n","    print(\"Número de lotes en val_loader:\", len(val_loader))\n","\n","    total_steps = len(train_loader) * n_epochs  # Total de pasos a realizar\n","    current_step = 0  # Paso actual\n","\n","    for epoch in range(1, n_epochs + 1):\n","        loss_train = 0.0\n","        for imgs, numeric_features, price in train_loader:\n","            current_step += 1  # Incrementa el paso actual\n","            imgs = imgs.to(device)\n","            numeric_features = numeric_features.to(device)\n","            price = price.to(device)\n","            output = model(imgs, numeric_features)\n","\n","            loss = loss_fn(output, price)\n","\n","            # L2 Regularization\n","            l2_lambda = 0.001\n","            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n","            loss = loss + l2_lambda * l2_norm\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            loss_train += loss.item()\n","\n","            # Calcular el porcentaje de avance y mostrarlo\n","            percent_complete = (current_step / total_steps) * 100\n","            print(f'\\rEpoch {epoch}, {percent_complete:.2f}% completado. Loss: {loss_train / current_step:.4f}', end='')\n","\n","        # Al final de cada época, imprime el resumen y evalúa en el conjunto de validación\n","        if epoch == 1 or epoch % 10 == 0:\n","            print(f'\\n{datetime.datetime.now()} Epoch {epoch}, Training loss {loss_train / len(train_loader)}')\n","            test_loop(dataloader=val_loader, model=model, loss_fn=loss_fn)\n","        else:\n","            # Imprime una nueva línea si no es una época de impresión, para evitar sobrescribir mensajes futuros\n","            print()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2eCwAC80rTxx"},"source":["## Train"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"elapsed":221,"status":"error","timestamp":1710096519098,"user":{"displayName":"Uriel Martinez","userId":"16113756077319415036"},"user_tz":360},"id":"JweZFoizrU1g","outputId":"451f0ca0-f8db-417b-96c7-d0459159242b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Número de lotes en train_loader: 6\n","Número de lotes en val_loader: 2\n"]},{"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (64x4 and 9x64)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[24], line 18\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(n_epochs, optimizer, model, loss_fn, train_loader, val_loader)\u001b[0m\n\u001b[0;32m     16\u001b[0m numeric_features \u001b[38;5;241m=\u001b[39m numeric_features\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m price \u001b[38;5;241m=\u001b[39m price\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, price)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# L2 Regularization\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\uriel\\OneDrive\\Escritorio\\Uriel\\IPN\\ESCOM\\TT\\Codigo\\my_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\uriel\\OneDrive\\Escritorio\\Uriel\\IPN\\ESCOM\\TT\\Codigo\\my_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[21], line 57\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# x = x.view(-1, 20*20*128)\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumeric_features_\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, y), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     59\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombined_features_(z)\n","File \u001b[1;32mc:\\Users\\uriel\\OneDrive\\Escritorio\\Uriel\\IPN\\ESCOM\\TT\\Codigo\\my_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\uriel\\OneDrive\\Escritorio\\Uriel\\IPN\\ESCOM\\TT\\Codigo\\my_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\uriel\\OneDrive\\Escritorio\\Uriel\\IPN\\ESCOM\\TT\\Codigo\\my_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[1;32mc:\\Users\\uriel\\OneDrive\\Escritorio\\Uriel\\IPN\\ESCOM\\TT\\Codigo\\my_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\uriel\\OneDrive\\Escritorio\\Uriel\\IPN\\ESCOM\\TT\\Codigo\\my_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\uriel\\OneDrive\\Escritorio\\Uriel\\IPN\\ESCOM\\TT\\Codigo\\my_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x4 and 9x64)"]}],"source":["training_loop(\n","n_epochs = 100,\n","optimizer = optimizer,\n","model = model,\n","loss_fn = loss_fn,\n","train_loader = train_dataloader,\n","val_loader=val_dataloader)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
